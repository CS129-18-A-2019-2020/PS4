{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d91f51ab-0e87-4aa3-8ddc-8c7ce5b627af"
    }
   },
   "source": [
    "# SVM Walkthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8ac83630-b24c-4780-a445-83f1dc4523cb"
    }
   },
   "source": [
    "This is a practice/laboratory session of SVM tutorial using Python. At the end of this tutorial you will learn the following:\n",
    "* How to train Support Vector Machine using your data\n",
    "* How to measure the performance of your training\n",
    "* How to predict the label of classification using the data that is not in the training data\n",
    "* To understand the role of kernel and cost parameter in improving the SVM performance\n",
    "* To understand the meaning of support vector\n",
    "* How to identify overfitting in SVM\n",
    "\n",
    "The topics are\n",
    "\n",
    "1. <a href='#linearlySeparable'>SVM for Linearly Separable Dataset</a>\n",
    "2. <a href='#linearlyNonSeparable'>SVM for Non-Linearly Separable Dataset</a>\n",
    "3. <a href='#oneDimensionSVM'>SVM for One Dimensional Dataset</a>\n",
    "\n",
    "Let us start. First, you need to import the necessary modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "265a3540-e0f3-4a28-967e-8e415888611b"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import sklearn.metrics as metric\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='linearlySeparable'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. SVM for Linearly Separable Dataset\n",
    "\n",
    "Our first dataset can be uploaded. Put the CSV files in the same folder as the Jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4c788d3f-383b-4db6-ab38-d865ea8a577f"
    }
   },
   "outputs": [],
   "source": [
    "filedata='data/SVM_Dataset1.csv'\n",
    "data1=pd.read_csv(filedata)\n",
    "data1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the X training data from the y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fb468229-6c95-47cd-98eb-3f52ed593e13"
    }
   },
   "outputs": [],
   "source": [
    "X1=data1['X1']\n",
    "X2=data1['X2']\n",
    "X_training=np.array(list(zip(X1,X2)))\n",
    "X_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "a1737a96-bcd7-43c5-804e-dd0a1eb05277"
    }
   },
   "outputs": [],
   "source": [
    "y_training=data1['y']\n",
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "target_names=['-1','+1']\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this data. Can you imagine a line separating the two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "d5a59677-a67e-4fe8-a530-ce3d685c88db"
    }
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2');\n",
    "plt.savefig('chart0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Vector Support Classification (SVC) algorithm, we need define the model **kernel**. Let us use  *linear kernel*. Then, we use the **fit()** function to train the model with our training data. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "79e31433-e980-4580-b893-7e3681b436fa"
    }
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear').fit(X_training,y_training)\n",
    "svc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the internal model parameters use **`get_params()`** method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.get_params(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The trained model can be plotted with specifying the **`decision_function()`** method.\n",
    "\n",
    "First, we set the boundary of the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbX1=math.floor(min(X_training[:,0]))-1\n",
    "ubX1=math.ceil(max(X_training[:,0]))+1\n",
    "lbX2=math.floor(min(X_training[:,1]))-1\n",
    "ubX2=math.ceil(max(X_training[:,1]))+1\n",
    "[lbX1,ubX1,lbX2,ubX2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "plt.contour(X,Y,Z,colors=['k'], linestyles=['-'],levels=[0])\n",
    "\n",
    "plt.title('Linearly Separable')\n",
    "plt.savefig('chart1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following plot show the margin and the support vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('Margin and Support Vectors')\n",
    "plt.savefig('chart2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of support vectors for each class can be revealed using **`n_support_'** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the indices (= the row numbers in the original dataset) of the support vectors, use **`support_`** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.support_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify the support vector, use **`support_vectors_`** attribute. The data that become the support vector are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear model, we can reveal the discriminant line that separate the classes using **`coef_`** and **`intercept_`** attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weight=svc.coef_\n",
    "intercept=svc.intercept_\n",
    "a = -weight[0,0] / weight[0,1]\n",
    "print('x2=',a,' * x1 + ',-intercept[0]/weight[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the normalize accuracy, of the training, we can use **score(X,y)** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.score(X_training, y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, if you have test sample, you can also use the metric from sklearn. To use this on the training sample, we first need to define the y-prediction (which is based on the prediction of the model with X comes from the training sample) and the y-true value (which is based on the y of the training sample)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred=svc.predict(X_training)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_true = y_training\n",
    "y_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The absolute accuracy is measured as follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metric.accuracy_score(y_true, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix is useful to see if there is misclassification. If there is no missclassification, then the corect values would be in the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cnf_matrix=metric.confusion_matrix(y_true, y_pred)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the confusion matrix through the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "# code from http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "    \n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=target_names, normalize=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Prediction\n",
    "\n",
    "Now we can also use the trained SVM to predict something that is outside the training data. Let us predict the class y of the given test data [X1, X2] = [3, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "22c28c9a-63e7-4846-b646-200755b3f53f"
    }
   },
   "outputs": [],
   "source": [
    "svc.predict([[3,6]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data is now plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "3fc1113a-0b1f-446b-8b56-4eb087731a98"
    }
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.scatter(3,6,c='r',marker='s',s=90)\n",
    "plt.legend(['-1','+1','prediction'],loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "plt.contour(X,Y,Z,colors=['k'], linestyles=['-'],levels=[0])\n",
    "\n",
    "plt.title('Prediction')\n",
    "plt.savefig('chart3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally (in case you have limited memory in our laptop), if you want to clear the memory for the next training data, you can delete the variables with large memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del X1, X2, X_training, y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='linearlyNonSeparable'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. SVM for Non Linearly Separable Dataset\n",
    "\n",
    "## Data\n",
    "Now we upload the second dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filedata='data/SVM_Dataset2.csv'\n",
    "data2=pd.read_csv(filedata)\n",
    "data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We separate the X training data from the y training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1=data2['x1']\n",
    "X2=data2['x2']\n",
    "X_training=np.array(list(zip(X1,X2)))\n",
    "X_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_training=data2['y']\n",
    "y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot this data. Can you imagine a line separating the two classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=3)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2');\n",
    "plt.savefig('nl-chart0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the plot show that no line can separate the two classes. If we still want to use linear kernel, we can define a regularization cost parameter **C**. We use the **fit()** function to train the model with our training data. Feel free to change the regularization parameter to make such that the error of classification would be minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbX1=math.floor(min(X_training[:,0]))-1\n",
    "ubX1=math.ceil(max(X_training[:,0]))+1\n",
    "lbX2=math.floor(min(X_training[:,1]))-1\n",
    "ubX2=math.ceil(max(X_training[:,1]))+1\n",
    "[lbX1,ubX1,lbX2,ubX2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear',C=0.001).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=3)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "plt.contour(X,Y,Z,colors=['k'], linestyles=['-'],levels=[0])\n",
    "plt.title('Non-Linearly Separable')\n",
    "plt.savefig('nl-chart1.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we increase the regularization parameter C=100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='linear',C=100).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=3)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('Linear Kernel with regularization')\n",
    "plt.savefig('nl-chart-regularization.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vectors\n",
    "\n",
    "The number of support vectors for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred=svc.predict(X_training)\n",
    "y_true = y_training\n",
    "metric.accuracy_score(y_true, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using linear kernel, we found 4 support vectors but one out of 20 data is in the wrong side. Thus the accuracy is 19 / 20 * 100 = 94.99%.\n",
    "\n",
    "It seems we are stuck with one misclassification.\n",
    "\n",
    "\n",
    "## Training with Polynomial Kernel\n",
    "\n",
    "Now it is the time to change the kernel into non-linear kernel. Let us try to use polynomial kernel.\n",
    "\n",
    "There is no misclassification if the degree = 2 and above.\n",
    "\n",
    "You can play with the degree and regularization parameter C.\n",
    "+ Will the number support vectors increase if you increase the degree?\n",
    "+ Will the number support vectors increase if you increase the regularization parameter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='poly',C=1, degree=2, probability=True).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=3)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('Polynomial Kernel')\n",
    "plt.savefig('nl-poly2-kernel.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that some of the support vectors are not the same point as the earlier support vectors using linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.support_vectors_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Just to give rough idea of overfitting, now let us use RBF kernel.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='rbf',C=1, gamma=3).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(['-1','+1'],loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('RBF Kernel gamma 1')\n",
    "plt.savefig('nl-RBF1-kernel.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred=svc.predict(X_training)\n",
    "y_true = y_training\n",
    "metric.accuracy_score(y_true, y_pred, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the training has reached 100% (20/20) due to the RBF kernel. However, look at the support vectors. The whole dataset becomes the support vectors and it is an indication that the RBF model overfit our data. Adding more data may need to change the model.\n",
    "\n",
    "Thus, in our example the Polynomial model with lower degree (degree 2) works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. One Dimensional SVM\n",
    "\n",
    "This problem at first may seem to be simpler problem. We have X in one dimension. However, the challenge is the scatter plot does not accept 1D training data.\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filedata='data/SVM_Dataset3.csv'\n",
    "data3=pd.read_csv(filedata)\n",
    "data3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual X data is just one dimension. The scatter plot will not work.\n",
    "\n",
    "To make it works, we need to add dummy X2 such that we can plot using scatter plot and train using SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X1=data3['x']\n",
    "X2=np.ones((len(X),1),int)\n",
    "X_training=np.array(list(zip(X1,X2)))  \n",
    "# X_training=np.array(np.transpose([X1])) # alternative way, but you cannot plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_training=data3['y']\n",
    "y_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=3)\n",
    "plt.xlabel('X1')\n",
    "plt.ylabel('X2');\n",
    "plt.savefig('data3-chart0.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM Training and Performance\n",
    "\n",
    "Now let us do the SVM training to this dataset and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lbX1=math.floor(min(X_training[:,0]))-1\n",
    "ubX1=math.ceil(max(X_training[:,0]))+1\n",
    "lbX2=math.floor(min(X_training[:,1]))-1\n",
    "ubX2=math.ceil(max(X_training[:,1]))+1\n",
    "[lbX1,ubX1,lbX2,ubX2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='poly',C=1, degree=2).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('Polynomial Kernel')\n",
    "plt.savefig('data3-Poly-kernel.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model has 9 support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='poly',C=1, degree=3).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('Polynomial Kernel')\n",
    "plt.savefig('data3-Poly-kernel.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have three support vector for Polynomial degree 3 and training accuracy of 100%. This should be the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overfitting\n",
    "\n",
    "Just for curiosity, we can also try to use RBF kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='rbf',C=1, gamma=3).fit(X_training,y_training)\n",
    "\n",
    "idxPlus=y_training[y_training<0].index\n",
    "idxMin=y_training[y_training>0].index\n",
    "plt.scatter(X_training[idxPlus,0],X_training[idxPlus,1],c='b',s=50)\n",
    "plt.scatter(X_training[idxMin,0],X_training[idxMin,1],c='r',s=50)\n",
    "plt.legend(target_names,loc=2)\n",
    "\n",
    "X,Y = np.mgrid[lbX1:ubX1:100j,lbX2:ubX2:100j]\n",
    "Z = svc.decision_function(np.c_[X.ravel(),Y.ravel()])\n",
    "Z = Z.reshape(X.shape)\n",
    "plt.contourf(X,Y,Z > 0,alpha=0.4)\n",
    "\n",
    "plt.contour(X,Y,Z,colors=['k','k','k'], linestyles=['--','-','--'],levels=[-1,0,1])\n",
    "plt.scatter(svc.support_vectors_[:,0],svc.support_vectors_[:,1],s=120,facecolors='none')\n",
    "plt.scatter(X_training[:,0],X_training[:,1],c=y_training,s=50,alpha=0.95);\n",
    "\n",
    "plt.title('RBF Kernel')\n",
    "plt.savefig('data3-RBF-kernel.png')\n",
    "\n",
    "svc.score(X_training,y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc.n_support_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just as before, the accuracy is 100% but the whole data sets now become support vectors. It is a clear sign of overfitting. When the whole dataset become support vectors, it implies that the model memorizes the data rather than generalizing it. Thus, we should avoid to use RBF for this dataset.\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "In conclusion, the support vectors in SVM are the quality data that we can use to generate the decision boundary (of the same model). Non-support vector data can be ignored, regardless how many data that you have. This also implies that SVM can overcome with ease the imbalance amount of data between classes. That is one of the strengths of SVM.\n",
    "\n",
    "When the number of support vectors represent the whole dataset, the model is overfit because it memorize the whole dataset and cannot be generalized to predict new data outside the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check: [SVM Tutorial in Microsoft Excel](http://people.revoledu.com/kardi/tutorial/SVM/purchase.html)\n",
    "\n",
    "Visit [www.Revoledu.com](http://people.revoledu.com/kardi/tutorial/) for more tutorials in Data Science\n",
    "\n",
    "Copyright © 2017 [Kardi Teknomo](http://people.revoledu.com/kardi/)\n",
    "\n",
    "Permission is granted to share this notebook as long as the copyright notice is intact."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nbpresent": {
   "slides": {
    "3496c299-b543-4a18-8e7b-ddba1a408fc5": {
     "id": "3496c299-b543-4a18-8e7b-ddba1a408fc5",
     "prev": "d1f9103b-9d36-4693-bedb-5e778ac7e6a4",
     "regions": {
      "e4a5656c-839c-4c72-8a78-1c925cebe8cd": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0fff3b7d-0a74-47e6-839d-156d9c106bc0",
        "part": "whole"
       },
       "id": "e4a5656c-839c-4c72-8a78-1c925cebe8cd"
      }
     }
    },
    "36c2bbe2-2aef-4901-8839-3f44920cf945": {
     "id": "36c2bbe2-2aef-4901-8839-3f44920cf945",
     "prev": "8bc7088b-791e-40d7-b914-c8c1019a51a8",
     "regions": {
      "73a5578d-3346-4d14-a21f-d59726577f30": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8ac83630-b24c-4780-a445-83f1dc4523cb",
        "part": "whole"
       },
       "id": "73a5578d-3346-4d14-a21f-d59726577f30"
      }
     }
    },
    "3c5869e8-ae2c-4c2d-80d6-e55ff433cb1c": {
     "id": "3c5869e8-ae2c-4c2d-80d6-e55ff433cb1c",
     "prev": "839fb513-f51c-4f67-8964-1fae61121a13",
     "regions": {
      "4299d1e3-21b6-4a71-b059-7ac1b4a8cfbc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6652d87b-cb06-4633-800a-ee67d63eacb8",
        "part": "whole"
       },
       "id": "4299d1e3-21b6-4a71-b059-7ac1b4a8cfbc"
      }
     }
    },
    "484ef155-7b5c-480d-816c-91b4c3925f4d": {
     "id": "484ef155-7b5c-480d-816c-91b4c3925f4d",
     "prev": "36c2bbe2-2aef-4901-8839-3f44920cf945",
     "regions": {
      "4d408ec9-6cda-4649-bb93-94753f9ddbcc": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "265a3540-e0f3-4a28-967e-8e415888611b",
        "part": "whole"
       },
       "id": "4d408ec9-6cda-4649-bb93-94753f9ddbcc"
      }
     }
    },
    "4f18e73e-46dc-4441-90cb-31bb2ab1fcc7": {
     "id": "4f18e73e-46dc-4441-90cb-31bb2ab1fcc7",
     "prev": "a9f59ef0-da40-47c1-a1c9-0c2c44ced194",
     "regions": {
      "fb8ec7ec-6e15-4fa8-ad7f-26a7287f8450": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "79e31433-e980-4580-b893-7e3681b436fa",
        "part": "whole"
       },
       "id": "fb8ec7ec-6e15-4fa8-ad7f-26a7287f8450"
      }
     }
    },
    "6b9cdad1-caa8-4e11-bb77-44c6c44f96fc": {
     "id": "6b9cdad1-caa8-4e11-bb77-44c6c44f96fc",
     "prev": "3496c299-b543-4a18-8e7b-ddba1a408fc5",
     "regions": {
      "ba42b53c-9819-406d-b99f-07e740a75f76": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "70b062d9-32aa-4d81-aced-8fff4b339012",
        "part": "whole"
       },
       "id": "ba42b53c-9819-406d-b99f-07e740a75f76"
      }
     }
    },
    "839fb513-f51c-4f67-8964-1fae61121a13": {
     "id": "839fb513-f51c-4f67-8964-1fae61121a13",
     "prev": "9bbabb46-0429-4b87-ae42-01d682678cb3",
     "regions": {
      "d82ca175-c7e7-40a8-b246-6bd9610fa734": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "513956da-c6c2-4ec5-b8cc-03396088899d",
        "part": "whole"
       },
       "id": "d82ca175-c7e7-40a8-b246-6bd9610fa734"
      }
     }
    },
    "8bc7088b-791e-40d7-b914-c8c1019a51a8": {
     "id": "8bc7088b-791e-40d7-b914-c8c1019a51a8",
     "prev": null,
     "regions": {
      "41b13598-2c73-48a0-a60c-47fb8caebc48": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d91f51ab-0e87-4aa3-8ddc-8c7ce5b627af",
        "part": "whole"
       },
       "id": "41b13598-2c73-48a0-a60c-47fb8caebc48"
      }
     }
    },
    "95f879b3-4f66-492d-a724-e9e34f3fc5d2": {
     "id": "95f879b3-4f66-492d-a724-e9e34f3fc5d2",
     "prev": "484ef155-7b5c-480d-816c-91b4c3925f4d",
     "regions": {
      "fc6af2cb-b063-461c-82c5-ae44e0087feb": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "4c788d3f-383b-4db6-ab38-d865ea8a577f",
        "part": "whole"
       },
       "id": "fc6af2cb-b063-461c-82c5-ae44e0087feb"
      }
     }
    },
    "9adff39c-b2f9-487f-a178-7b42ca7f49d6": {
     "id": "9adff39c-b2f9-487f-a178-7b42ca7f49d6",
     "prev": "95f879b3-4f66-492d-a724-e9e34f3fc5d2",
     "regions": {
      "201f1480-ecaa-4a7e-84de-02e8bda224b9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fb468229-6c95-47cd-98eb-3f52ed593e13",
        "part": "whole"
       },
       "id": "201f1480-ecaa-4a7e-84de-02e8bda224b9"
      }
     }
    },
    "9bbabb46-0429-4b87-ae42-01d682678cb3": {
     "id": "9bbabb46-0429-4b87-ae42-01d682678cb3",
     "prev": "c38224a4-e981-4109-a863-21537db55987",
     "regions": {
      "e1f891df-2a54-4da7-85aa-b4fb01e8aba9": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "3fc1113a-0b1f-446b-8b56-4eb087731a98",
        "part": "whole"
       },
       "id": "e1f891df-2a54-4da7-85aa-b4fb01e8aba9"
      }
     }
    },
    "a9f59ef0-da40-47c1-a1c9-0c2c44ced194": {
     "id": "a9f59ef0-da40-47c1-a1c9-0c2c44ced194",
     "prev": "e8632f51-1d64-4964-a29e-c1c955c24d89",
     "regions": {
      "4ea234fb-5c7e-4d1a-89ce-72f7c0c9fb78": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d5a59677-a67e-4fe8-a530-ce3d685c88db",
        "part": "whole"
       },
       "id": "4ea234fb-5c7e-4d1a-89ce-72f7c0c9fb78"
      }
     }
    },
    "c38224a4-e981-4109-a863-21537db55987": {
     "id": "c38224a4-e981-4109-a863-21537db55987",
     "prev": "4f18e73e-46dc-4441-90cb-31bb2ab1fcc7",
     "regions": {
      "6bbc032e-fa32-47f2-b0ee-f70243ae7029": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "22c28c9a-63e7-4846-b646-200755b3f53f",
        "part": "whole"
       },
       "id": "6bbc032e-fa32-47f2-b0ee-f70243ae7029"
      }
     }
    },
    "d1f9103b-9d36-4693-bedb-5e778ac7e6a4": {
     "id": "d1f9103b-9d36-4693-bedb-5e778ac7e6a4",
     "prev": "3c5869e8-ae2c-4c2d-80d6-e55ff433cb1c",
     "regions": {
      "20d6efc1-ab54-4be1-b71e-68ad1db88d73": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9f79c7bc-3235-4a57-93e9-7f38258ae415",
        "part": "whole"
       },
       "id": "20d6efc1-ab54-4be1-b71e-68ad1db88d73"
      }
     }
    },
    "d822e162-cbb4-46ec-aa7d-847eeaba5588": {
     "id": "d822e162-cbb4-46ec-aa7d-847eeaba5588",
     "prev": "6b9cdad1-caa8-4e11-bb77-44c6c44f96fc",
     "regions": {
      "6347d5dc-5968-4e81-9e33-e31925d0f774": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "7040ccfb-4f8f-4200-a68e-4a6a1ad4818f",
        "part": "whole"
       },
       "id": "6347d5dc-5968-4e81-9e33-e31925d0f774"
      }
     }
    },
    "e8632f51-1d64-4964-a29e-c1c955c24d89": {
     "id": "e8632f51-1d64-4964-a29e-c1c955c24d89",
     "prev": "9adff39c-b2f9-487f-a178-7b42ca7f49d6",
     "regions": {
      "621a7440-6fb1-4d63-9261-0312f2d31c53": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "a1737a96-bcd7-43c5-804e-dd0a1eb05277",
        "part": "whole"
       },
       "id": "621a7440-6fb1-4d63-9261-0312f2d31c53"
      }
     }
    }
   },
   "themes": {
    "default": "d52a3c17-7ddb-4baa-b18c-2f405795cbfe",
    "theme": {
     "d52a3c17-7ddb-4baa-b18c-2f405795cbfe": {
      "id": "d52a3c17-7ddb-4baa-b18c-2f405795cbfe",
      "palette": {
       "19cc588f-0593-49c9-9f4b-e4d7cc113b1c": {
        "id": "19cc588f-0593-49c9-9f4b-e4d7cc113b1c",
        "rgb": [
         252,
         252,
         252
        ]
       },
       "31af15d2-7e15-44c5-ab5e-e04b16a89eff": {
        "id": "31af15d2-7e15-44c5-ab5e-e04b16a89eff",
        "rgb": [
         68,
         68,
         68
        ]
       },
       "50f92c45-a630-455b-aec3-788680ec7410": {
        "id": "50f92c45-a630-455b-aec3-788680ec7410",
        "rgb": [
         155,
         177,
         192
        ]
       },
       "c5cc3653-2ee1-402a-aba2-7caae1da4f6c": {
        "id": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "rgb": [
         43,
         126,
         184
        ]
       },
       "efa7f048-9acb-414c-8b04-a26811511a21": {
        "id": "efa7f048-9acb-414c-8b04-a26811511a21",
        "rgb": [
         25.118061674008803,
         73.60176211453744,
         107.4819383259912
        ]
       }
      },
      "rules": {
       "blockquote": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410"
       },
       "code": {
        "font-family": "Anonymous Pro"
       },
       "h1": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 8
       },
       "h2": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 6
       },
       "h3": {
        "color": "50f92c45-a630-455b-aec3-788680ec7410",
        "font-family": "Lato",
        "font-size": 5.5
       },
       "h4": {
        "color": "c5cc3653-2ee1-402a-aba2-7caae1da4f6c",
        "font-family": "Lato",
        "font-size": 5
       },
       "h5": {
        "font-family": "Lato"
       },
       "h6": {
        "font-family": "Lato"
       },
       "h7": {
        "font-family": "Lato"
       },
       "pre": {
        "font-family": "Anonymous Pro",
        "font-size": 4
       }
      },
      "text-base": {
       "font-family": "Merriweather",
       "font-size": 4
      }
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
